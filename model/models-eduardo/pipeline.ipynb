{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modeling using modular pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: iopro\n",
      "Message: trial mode expires in 28 days\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from IPython.display import display, HTML \n",
    "from sklearn import ensemble, linear_model, svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "# Add pipeline_src to include path\n",
    "path = \"../../pipeline_src/\"\n",
    "if not path in sys.path:\n",
    "    sys.path.insert(1, path)\n",
    "del path\n",
    "\n",
    "from experiment import Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Configure parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#All features that have the following prefix will be deleted\n",
    "#['mun_pop', 'mun_nat', 'mun_car', 'mun_nmn', 'mun_region', 'mun_geo']\n",
    "prefixes_to_delete = ['mun_pop', 'mun_nat', 'mun_car', 'mun_nmn', 'mun_geo']\n",
    "#The following columns will be deleted just before training\n",
    "#'colonia_num_abd'\n",
    "features_to_delete = ['coloniaid', 'colonia_num_loans','abandoned', 'nom_mun', 'cve',\n",
    "                      'cv_credito', 'cur_year', 'past', 'year_granted', 'abandon_year', 'abandon_month']\n",
    "#How many cores, sir?\n",
    "cores = 25\n",
    "#Class_weights\n",
    "cw = 'auto'\n",
    "#Class_weights for tree based models\n",
    "cw_tree = 'subsample'\n",
    "#Number of estimators\n",
    "n_est = 100\n",
    "#Feature scaling?\n",
    "feature_scaling = False\n",
    "#Dropping nas?\n",
    "drop_criteria = 'col'\n",
    "#Subsample ratio?\n",
    "subsample_ratio = None\n",
    "#Save results to SQL table=\n",
    "save_to_sql = True\n",
    "#Set a common name for the models run here\n",
    "#output files will be\n",
    "#prefix_model_name_date.html\n",
    "prefix = \"lrcv_cw_auto_only_ecuve_region\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Declare models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Models with class_weight â€“ try auto and subsample\n",
    "\n",
    "#ExtraTreesClassifier\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n",
    "et = ensemble.ExtraTreesClassifier(n_estimators=n_est, class_weight=cw_tree, n_jobs=cores)\n",
    "\n",
    "#RandomForestClassifier\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=n_est, class_weight=cw_tree, n_jobs=cores)\n",
    "\n",
    "#RidgeClassifier\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier\n",
    "rc = linear_model.RidgeClassifier(class_weight=cw)\n",
    "\n",
    "#SGDClassifier\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\n",
    "sgd = linear_model.SGDClassifier(class_weight=cw, n_jobs=cores)\n",
    "\n",
    "#LinearSVC\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "lsvc = svm.LinearSVC(class_weight=cw)\n",
    "\n",
    "#SVC\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "svc = svm.SVC(class_weight=cw)\n",
    "\n",
    "#LogisticRegressionCV\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "lrcv = linear_model.LogisticRegressionCV(class_weight=cw, n_jobs=cores)\n",
    "\n",
    "#LogisticRegression\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "lr = linear_model.LogisticRegression(class_weight=cw)\n",
    "\n",
    "#Create a list of models\n",
    "#models = [rf, lsvc, lrcv]\n",
    "models = [lrcv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Given a model, get the name of the class to name the report file\n",
    "def filename_for_model(model, extension):\n",
    "    s = str(type(model))\n",
    "    class_name = re.search(\".*'(.+?)'.*\", s).group(1).split(\".\")[-1]\n",
    "    return prefix+\"_\"+class_name+\".\"+extension\n",
    "#Given the name of a file, return the contents of it\n",
    "def render_html(html_file):\n",
    "    file = open(html_file, 'r')\n",
    "    return file.read()\n",
    "#Given a list of prefixes, return features\n",
    "#that contain a prefix given by the user\n",
    "def contains_prefix(s, prefixes_list):\n",
    "    result = sum([s.startswith(prefix) for prefix in prefixes_list])\n",
    "    return result > 0\n",
    "def list_features():\n",
    "    return list(exp.x_train)\n",
    "def list_feature_groups():\n",
    "    features = list(exp.x_train)\n",
    "    prefixes =  map(lambda x: x.split(\"_\")[0], features)\n",
    "    unique = set(prefixes) \n",
    "    return unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from file /mnt/data/infonavit/master_loan_features/master_loan_features_v4.h5...\n",
      "Opening /mnt/data/infonavit/master_loan_features/master_loan_features_v4.h5 in read-only mode\n",
      "Training Data loaded.\n",
      "Loading Testing data...\n",
      "Opening /mnt/data/infonavit/master_loan_features/master_loan_features_v4.h5 in read-only mode\n",
      "Data loading complete\n",
      ".x_train.shape = (1369239, 583)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 583)\n",
      ".y_test.shape = (1570992,)\n",
      "Training on: (2008, 2012)\n",
      "Testing on: (2012, 2013)\n"
     ]
    }
   ],
   "source": [
    "#Instantiate experiment\n",
    "exp = Experiment()\n",
    "exp.load_data_hdf()\n",
    "#Print training and testing range\n",
    "print 'Training on: '+str(exp.train_range)\n",
    "print 'Testing on: '+str(exp.test_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape before dropping columns:\n",
      ".x_train.shape = (1369239, 583)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 583)\n",
      ".y_test.shape = (1570992,)\n",
      "New shape after dropping:\n",
      ".x_train.shape = (1369239, 541)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 541)\n",
      ".y_test.shape = (1570992,)\n"
     ]
    }
   ],
   "source": [
    "#Drop mun features (new table will be loaded from a csv file)\n",
    "old_mun_features = filter(lambda x: contains_prefix(x, [\"mun\"]) , list_features())\n",
    "exp.drop_cols(old_mun_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Map some features to bools\n",
    "dic = {'f':0, 't': 1}\n",
    "exp.x_train['loan_has_subsudy'] = exp.x_train['loan_has_subsudy'].map(dic)\n",
    "exp.x_train['loan_voluntary_contrib_bool'] = exp.x_train['loan_voluntary_contrib_bool'].map(dic)\n",
    "\n",
    "exp.x_test['loan_has_subsudy'] = exp.x_train['loan_has_subsudy'].map(dic)\n",
    "exp.x_test['loan_voluntary_contrib_bool'] = exp.x_train['loan_voluntary_contrib_bool'].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load master municipality features table\n",
    "mun_features = pd.read_csv(\"/mnt/scratch/master_muns_features.csv\")\n",
    "mun_features.rename(columns={'mun_cve': 'cve', 'mun_year': 'cur_year'}, inplace=True)\n",
    "#Add features to experiment object\n",
    "exp.x_train = pd.merge(exp.x_train, mun_features, on=('cve', 'cur_year'))\n",
    "exp.x_test = pd.merge(exp.x_test, mun_features, on=('cve', 'cur_year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545,)\n",
      "(503,)\n",
      "(528,)\n"
     ]
    }
   ],
   "source": [
    "print mun_features['cve'].unique().shape\n",
    "print exp.x_train['cve'].unique().shape\n",
    "print exp.x_test['cve'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting:\n",
      "['coloniaid', 'colonia_num_loans', 'abandoned', 'nom_mun', 'cve', 'cv_credito', 'cur_year', 'past', 'year_granted', 'abandon_year', 'abandon_month']\n",
      "Original shape before dropping columns:\n",
      ".x_train.shape = (1369239, 690)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 690)\n",
      ".y_test.shape = (1570992,)\n",
      "New shape after dropping:\n",
      ".x_train.shape = (1369239, 679)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 679)\n",
      ".y_test.shape = (1570992,)\n"
     ]
    }
   ],
   "source": [
    "print 'Deleting:'\n",
    "print features_to_delete\n",
    "#Drop features\n",
    "exp.drop_cols(features_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape before dropping columns:\n",
      ".x_train.shape = (1369239, 679)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 679)\n",
      ".y_test.shape = (1570992,)\n",
      "New shape after dropping:\n",
      ".x_train.shape = (1369239, 541)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 541)\n",
      ".y_test.shape = (1570992,)\n"
     ]
    }
   ],
   "source": [
    "#Remove features that match prefix given in the configuration cell\n",
    "matches_prefix = filter(lambda x: contains_prefix(x, prefixes_to_delete), list_features())\n",
    "matches_prefix\n",
    "exp.drop_cols(matches_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of dataframes before dropping NA's:\n",
      ".x_train.shape = (1369239, 541)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 541)\n",
      ".y_test.shape = (1570992,)\n",
      "NA's found in the following columns. Dropping: set(['colonia_avg_water_escore', 'sustainability_escore_relative', 'colonia_avg_transportation_escore', 'schools_escore_relative', 'water_escore', 'parks_escore_relative', 'colonia_avg_hospital_escore', 'sustainability_escore', 'colonia_avg_power_escore', 'water_escore_relative', 'colonia_avg_community_escore', 'colonia_avg_markets_escore', 'hospital_escore_relative', 'digital_escore_relative', 'equip_escore_relative', 'roads_transport_escore_relative', 'colonia_avg_digital_escore', 'personal_risk_index', 'satisfaction_escore_relative', 'loan_subaccount_value_relative', 'colonia_avg_validitiy_index_escore', 'colonia_avg_references_escore', 'power_escore_relative', 'references_escore_relative', 'roads_transport_escore', 'colonia_avg_sustainability_escore', 'transportation_escore_relative', 'total_escore_relative', 'living_area_escore_relative', 'housing_quality_escore_relative', 'colonia_avg_parks_escore', 'hospital_escore', 'validitiy_index_escore_relative', 'housing_quality_escore', 'community_escore', 'equip_escore', 'colonia_avg_roads_transport_escore', 'loan_voluntary_contrib_bool', 'markets_escore_relative', 'validitiy_index_escore', 'references_escore', 'colonia_avg_housing_quality_escore', 'digital_escore', 'parks_escore', 'loan_has_subsudy', 'colonia_avg_living_area_escore', 'colonia_avg_total_escore', 'transportation_escore', 'colonia_avg_satisfaction_escore', 'community_escore_relative', 'markets_escore', 'satisfaction_escore', 'schools_escore', 'total_escore', 'power_escore', 'colonia_avg_schools_escore', 'loan_subaccount_value', 'living_area_escore', 'colonia_avg_equip_escore'])\n",
      "New shape after dropping:\n",
      ".x_train.shape = (1369239, 482)\n",
      ".y_train.shape = (1369239,)\n",
      ".x_test.shape = (1570992, 482)\n",
      ".y_test.shape = (1570992,)\n"
     ]
    }
   ],
   "source": [
    "#Drop columns with nas\n",
    "exp.drop_nas(drop_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Count per colums\n",
    "#is_na = exp.x_train.isnull()\n",
    "#nas_count = is_na.apply(sum, axis=0)\n",
    "#Filter for columns with more than 0 nas\n",
    "#col_names = nas_count[nas_count > 0]\n",
    "#print \"These columns have nas: \"+str(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Perform feature scaling if needed\n",
    "if feature_scaling:\n",
    "    exp.scale_features_training()\n",
    "    exp.scale_features_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subsample the training set into exp.x_train_sub with the specified ratio\n",
    "if subsample_ratio:\n",
    "    exp.subsample_training(subsample_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit the models\n",
    "fits = [model.fit(exp.x_train, exp.y_train) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "#train_scores = [fit.score(exp.x_train, exp.y_train) for fit in fits]\n",
    "#test_scores =  [fit.score(exp.x_train, exp.y_train) for fit in fits]\n",
    "#print train_scores, test_scores\n",
    "#print train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model evaluation and report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate HTML reports\n",
    "htmls = []\n",
    "for fitted_model in fits:\n",
    "    print \"Evaluating model \"+filename_for_model(fitted_model, \"\")\n",
    "    exp.test_model(fitted_model)\n",
    "    html = exp.eval_model(fitted_model, \"./\"+filename_for_model(fitted_model, \"html\"), save_to_sql=save_to_sql)\n",
    "    htmls.append(html)\n",
    "\n",
    "print htmls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Report rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Render html (IPython notebook)\n",
    "for html in htmls:\n",
    "    get_ipython().run_cell_magic(u'HTML', u'', render_html(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
